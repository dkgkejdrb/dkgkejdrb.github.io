---
layout: single
title:  "논문 리뷰(8): A Critical Review of Large Language Model on Software Engineering: An Example from ChatGPT and Automated Program."
categories: 석사_컴퓨터공학
tag: [석사_컴퓨터공학]
toc: true
















---

## 1. 논문 정보

- 제목: A Critical Review of Large Language Model on Software Engineering: An Example from ChatGPT and Automated Program
- 저자: Quanjun Zhang et al
- doi: https://doi.org/10.48550/arXiv.2310.08879
- 키워드: Automated Program Repair, Large Language Model, AI4SE

------

## 2. 요약

 Automated Program Repair(APR) 분야에서 ChatGPT는 기존의 최첨단 APR 기술을 능가하는 결과를 보여주었다. 예를 들어, ChatGPT는 QuickBugs 벤치마크에서 40개 버그 중 31개를 수정하였고, Defects4J 벤치마크에서도 상당수의 버그를 성공적으로 수정했다. 그러나 데이터 누출로 인한 평가의 어려움이 존재한다. 데이터 누출은 LLM이 인터넷에서 얻은 방대한 데이터로 훈련되는 과정에서 발생할 수 있으며, 이는 APR 작업에 일반적으로 사용되는 데이터셋(예: Defects4J, QuixBugs)이 훈련 데이터에 포함될 가능성이 있음을 의미한다. 따라서, ChatGPT가 훈련 중에 이미 평가 데이터셋을 본 경우가 있는지 확실히 알 수 없으며, 이는 평가 과정에서 모델의 성능을 과대 평가할 위험이 있다.

 이 논문은 SE 커뮤니티에서 주로 간과되어 온 데이터 누출 문제와 블랙박스 LLM이 코드 관련 작업에 적용될 때 발생할 수 있는 중요한 우려를 제기한다. ChatGPT와 APR을 각각 LLM과 SE 작업의 대표적인 예로 선택하였고, 프로그래밍 대회 플랫폼인 AtCoder에서 2023년 대회 문제와 사용자 제출물을 수집하여 새로운 데이터셋인 EvalGPTFix를 구축하였다.

- 원시 데이터 수집: 2023년부터 시작된 AtCoder 대회의 모든 Java 제출물을 크롤링하였다.
- 버그 코드의 수정 diff 확보: 버그가 있는 프로그램과 올바른 프로그램 사이의 6개 토큰 미만의 차이를 가진 쌍만 유지하였다.
- 테스트 케이스 추출: AtCoder 문제의 전용 데이터베이스에서 더 많은 공개 테스트 케이스를 다운로드하였다.
- 정적 기반 필터링: 반복 제출물을 제거하고, 코드 내의 주석을 삭제하여 APR 도구의 판단에 영향을 미치지 않도록 하였다.
- 동적 기반 필터링: 남은 모든 제출물을 각 문제에 관련된 모든 테스트 케이스에 대해 실행하였으며, 테스트 케이스에 실패하는 경우 해당 쌍을 제거하였다.

 이 논문은 EvalGPTFix 데이터셋을 활용하여 ChatGPT의 APR 분야에서의 성능을 평가하기 위해 세가지 연구 질문을 설계하였다.

- RQ1: EvalGPTFix에서 버그가 있는 프로그램을 수정하는 데 있어서 ChatGPT의 성능은 어떠한가?
- RQ2: 추가적인 프로그램 정보가 포함된 다양한 프롬프트가 ChatGPT의 성능에 어떤 영향을 미치는가?
- RQ3: 동적 실행 피드백과의 상호작용이 ChatGPT의 성능에 어떻게 영향을 미치는가?

------

## 3. 결론

 실험 결과 ChatGPT의 APR 능력 평가에 대한 세 가지 연구 질문에 다음과 같은 결과를 확인할 수 있었다.

 **RQ1:** ChatGPT는 기본 프롬프트를 제공받았을 때, 151개 중 109개의 버그를 수정할 수 있었다. 

  ![그림입니다. 원본 그림의 이름: CLP0000520429a6.bmp 원본 그림의 크기: 가로 509pixel, 세로 153pixel](../../images/2024-06-27-a9/EMB00003e582da2.bmp)  



 **RQ2:** 프로그래밍 문제 설명, 오류 메시지, 버그 위치를 프롬프트에 추가하면 각각 18개, 25개, 10개의 추가 버그가 수정되었다.

  ![그림입니다. 원본 그림의 이름: CLP000052040001.bmp 원본 그림의 크기: 가로 998pixel, 세로 633pixel](../../images/2024-06-27-a9/EMB00003e582da5.bmp)  



 **RQ3:** 대화를 통해 ChatGPT는 기본 프롬프트나 오류 정보가 포함된 프롬프트로 수정되지 않은 9개의 버그를 수정할 수 있었다.

  ![그림입니다. 원본 그림의 이름: CLP000052040002.bmp 원본 그림의 크기: 가로 507pixel, 세로 268pixel](../../images/2024-06-27-a9/EMB00003e582da8.bmp)  

------

## 4. 느낀점

 SE 분야에서 버그 수정 작업을 수행할 때 **데이터 누출**로 인해 LLM의 성능이 과대평가될 가능성을 확인하고, 이는 제가 실무 개발에서 LLM을 사용하면서 경험한 모호한 답변과 일관되지 않는 성능에 대한 이전의 느낌과 일치했습니다. 이 논문을 통해, 제 논문 주제인 프로그래밍 학습을 위한 코드 피드백 제공뿐만 아니라 GPT가 개발 현장에서의 활용성과 버그 수정 성능에서 다른 LLM들(CodeT5, PLBart)을 능가한다는 사실을 확인할 수 있었습니다.

 데이터 수집 및 전처리 과정에서 주석의 존재 유무가 LLM의 성능에 미치는 영향을 발견한 것은 특히 흥미로웠습니다. 이는 제 연구에서도 코드 내 주석을 제거하는 단계를 포함해야 한다는 것을 시사합니다. 또한, 버그 수정 성능을 개선하기 위해 프롬프트에 문제 설명, 오류 메시지, 버그 위치를 추가하는 것이 효과적임을 알게 되었습니다. 이는 제 연구의 프롬프트 설계에 큰 도움이 될 것으로 기대됩니다.

 또한, LLM을 이용한 코드 데이터 수집 시 충분한 데이터를 확보하려면 코드 생성과 코드 리뷰를 동일한 모델로 진행해서는 안 된다는 중요한 사실을 깨달았습니다. 제 연구에서 코드 생성에는 LLaMA를, 리뷰에는 ChatGPT를 사용하는 것이 오버핏과 데이터 누출 이슈를 방지하기 위한 최소한의 전략임을 알게 되었습니다.