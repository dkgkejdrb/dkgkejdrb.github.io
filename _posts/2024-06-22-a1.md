---
layout: single
title:  "논문 리뷰(1): Can large language models provide useful feedback on research papers? A large-scale empirical analysis."
categories: 석사_컴퓨터공학
tag: [석사_컴퓨터공학]
toc: true















---

### 들어가기 전에

석사 학위 논문을 위해 준비했던 과정들을 회고하고 아카이빙 하려고 한다. 논문 작성을 위해, 문헌조사를 통해 내가 생각하는 논문 주제와 관련된 논문을 조사했으며 이후에는 개인 연구를 진행하며 프로젝트 보고서를 작성했다. 이러한 일련의 과정을 전반적으로 다루어보려고 한다.

-----------------------

## 1. 논문 정보

- 제목: Can large language models provide useful feedback on research papers? A large-scale empirical analysis
- 저자: Weixin Lian et al
- doi: **[ arXiv:2310.01783](https://arxiv.org/abs/2310.01783)**
- 키워드: LLM, Fine-tuning, feedback

----

## 2. 요약

 전문가 피드백은 엄격한 연구의 기초를 마련하지만, 학술 연구의 급속한 증가와 지식 전문화의 복잡성으로 인해 경험이 적거나 자원이 부족한 연구자들이 적시에 피드백을 받기가 점점 어려워지고 있다. 이러한 상황에서, GPT-4와 같은 대규모 언어 모델(LLM)을 활용하여 연구 논문에 과학적 피드백을 제공하는 방법에 대한 관심이 증가하고 있다. 그러나 LLM을 통한 피드백의 유용성은 아직 체계적으로 연구되지 않았다. 이러한 격차를 해소하기 위해, 본 연구에서는 **과학 논문에 피드백을 제공하는** **GPT-4** **기반 자동화 파이프라인**을 개발하였다. 이 파이프라인은 세 단계로 구성되어있다. 첫 번째 단계에서는 제공된 PDF에서 논문의 제목, 초록, 그림 및 표, 본문을 추출하여 프롬프트를 구성한다. 그 후 GPT-4에게 주요 저널의 피드백 구조에 따라 중요성 및 새로움, 승인 가능성의 잠재적 이유, 거부 가능성의 잠재적 이유, 그리고 개선을 위한 제안으로 구성된 구조화된 피드백을 제공하도록 요청한다.

 두 번째 단계에서는 총 3,096편의 Nature 계열 논문과 1,709편의 ICLR 논문에 대한 LLM 피드백을 인간 피드백과 체계적으로 비교한다. 이를 위해 두 단계 코멘트 매칭 파이프라인을 사용한다. 파이프라인은 먼저 LLM과 인간이 작성한 피드백에서 주요 코멘트의 요점을 추출하는 텍스트 요약을 수행한 후, 의미론적 텍스트 매칭을 통해 LLM과 인간 피드백 간의 공유 코멘트 포인트를 매칭한다.

 마지막으로 AI 및 컴퓨터 생물학 분야의 미국 내 110개 기관의 308명 연구자들을 대상으로 한 잠재 사용자 연구조사를 실시한다. 연구자들은 자신이 저술한 논문을 업로드하고, 해당 논문에 대해 GPT-4 시스템이 생성한 피드백에 대한 설문조사에 참여한다. 이 연구는 연구자들이 LLM 피드백을 어떻게 인식하는지에 대한 중요한 통찰을 얻기 위함이다.

---

## 3. 결론

 본 연구에서는 두 가지 대규모 연구를 통해 GPT-4를 활용한 파이프라인으로 생성된 피드백의 품질을 평가하였다. 첫 번째로 GPT-4가 생성한 피드백을 Nature 계열 논문 3,096편과 ICLR 논문 1,709편의 인간 평가자의 피드백과 비교 분석하였다. GPT-4와 인간 평가자 간의 평균 일치율은 Nature 저널에서 30.85%, ICLR에서 39.23로 나타났으며, 이는 두 명의 인간 평가자 간 일치율(Nature: 28.58%, ICLR: 35.25%)과 유사한 수준이었다. 특히, 거부된 ICLR 논문에서는 GPT-4와 인간 평가자 간의 평균 일치율이 43.80%로, 더 높은 일치율을 보였다.

 마지막으로, AI 및 컴퓨터 생물학 분야의 미국 내 110개 기관의 308명 연구자들을 대상으로 한 연구에서, 연구자들은 자신의 논문에 대한 GPT-4 시스템의 피드백을 어떻게 받아들이는지 평가하였다. 전체적으로, 사용자의 절반 이상(57.4%)이 GPT-4가 생성한 피드백을 유용하거나 매우 유용하다고 평가했으며, 82.4%는 적어도 일부 인간 평가자의 피드백보다 더 유익하다고 생각했다. 그러나 GPT-4는 특정 과학적 피드백 측면(예: ‘더 많은 데이터셋에 대한 실험 추가’)에 집중하는 경향이 있으며, 방법론 설계에 대한 심층적인 비판을 제공하는 데 어려움을 겪는 것으로 나타났다.

---

## 4. 느낀점

 본 논문을 연구하며 GPT-4 기반의 자동화 파이프라인을 통해 유용한 피드백을 생성하는 과정을 깊이 이해할 수 있었습니다. 제 연구 계획에서 초등학생 학습자가 작성한 연구 문서에 대해 GPT-4 모델을 파인 튜닝하여 피드백을 제공하는 것만으로는 한계가 있음을 깨달았습니다. 하지만 본 논문에서 제시된 파이프라인의 두 번째 단계, 즉 LLM과 인간이 작성한 피드백에서 중요한 포인트를 추출해 텍스트 요약을 수행하고, 이를 의미론적 텍스트 매칭을 통해 비교하는 방식은 매우 효과적인 피드백 생성 방법으로 보입니다.

 그러나 실제 파이프라인의 소스코드를 분석해본 결과, 첫 번째 단계는 구현되어 있었지만, 유용한 피드백을 제공하기 위한 두 번째 단계의 코드는 존재하지 않음을 확인했습니다. 논문의 저자가 의도적으로 코드를 공유했든, 공유하지 않았든 간에, 완전한 자동화를 구현한 코드를 직접 테스트해볼 수 없다는 점이 아쉬웠습니다.

 하지만 본 논문을 통해 얻은 아이디어는 매우 유용하며, 이를 실현하기 위해 회사로부터 초등학생 학습자가 작성한 연구 문서의 데이터베이스에 접근할 계획입니다. 데이터베이스의 레이블과 값들을 통해 파인 튜닝을 위한 전처리 단계를 어떻게 진행할지 계획을 세워야 할 것입니다. 이 과정은 GPT-4를 활용한 자동화된 피드백 시스템을 개발하는 데 있어 중요한 초석이 될 것입니다. 이를 통해 어린 학습자들이 작성한 문서에 대한 효율적이고 정확한 피드백을 제공하는 데 한 걸음 더 다가갈 수 있을 것으로 기대합니다.